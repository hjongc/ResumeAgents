# ResumeAgents ìƒì„¸ ì‚¬ìš©ë²• ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” ResumeAgentsë¥¼ ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ì‚¬ìš©ìë¶€í„° ê³ ê¸‰ ê¸°ëŠ¥ì„ í™œìš©í•˜ê³ ì í•˜ëŠ” ì‚¬ìš©ìê¹Œì§€ ëª¨ë“  ë ˆë²¨ì˜ ì‚¬ìš©ìë¥¼ ìœ„í•œ ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [ì‹œì‘í•˜ê¸°](#1-ì‹œì‘í•˜ê¸°)
2. [í”„ë¡œí•„ ìƒì„± ë° ê´€ë¦¬](#2-í”„ë¡œí•„-ìƒì„±-ë°-ê´€ë¦¬)
3. [ìê¸°ì†Œê°œì„œ ì‘ì„± í”„ë¡œì„¸ìŠ¤](#3-ìê¸°ì†Œê°œì„œ-ì‘ì„±-í”„ë¡œì„¸ìŠ¤)
4. [ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í™œìš©](#4-ê³ ê¸‰-ê²€ìƒ‰-ê¸°ëŠ¥-í™œìš©)
5. [ê²°ê³¼ ë¶„ì„ ë° í™œìš©](#5-ê²°ê³¼-ë¶„ì„-ë°-í™œìš©)
6. [ë¬¸ì œ í•´ê²°](#6-ë¬¸ì œ-í•´ê²°)

## 1. ì‹œì‘í•˜ê¸°

### 1.1 í™˜ê²½ ì„¤ì •

```bash
# 1) í”„ë¡œì íŠ¸ í´ë¡  ë° ì´ë™
git clone https://github.com/hjongc/ResumeAgents.git
cd ResumeAgents

# 2) ê°€ìƒí™˜ê²½ ìƒì„± (Python 3.8+ í•„ìš”)
python -m venv venv

# 3) ê°€ìƒí™˜ê²½ í™œì„±í™”
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# 4) ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 5) ê³ ê¸‰ ê¸°ëŠ¥ì„ ìœ„í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ (ê¶Œì¥)
pip install sentence-transformers faiss-cpu
```

### 1.2 API í‚¤ ì„¤ì •

```bash
# í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì • (ê¶Œì¥)
export OPENAI_API_KEY="your_openai_api_key_here"

# ë˜ëŠ” .env íŒŒì¼ì— ì €ì¥
echo "OPENAI_API_KEY=your_openai_api_key_here" >> .env
```

### 1.3 ì²« ì‹¤í–‰ í…ŒìŠ¤íŠ¸

```bash
# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python main.py

# ë˜ëŠ” Python ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸
python -c "
from resumeagents.utils import ProfileManager
pm = ProfileManager(mode='light')
print('âœ… ResumeAgents ì„¤ì¹˜ ì™„ë£Œ!')
"
```

## 2. í”„ë¡œí•„ ìƒì„± ë° ê´€ë¦¬

### 2.1 ProfileManager ì´ˆê¸°í™”

```python
from resumeagents.utils import ProfileManager

# Light Mode (ê¸°ë³¸): JSON ê¸°ë°˜, ë¹ ë¥¸ ì²˜ë¦¬
pm_light = ProfileManager(mode='light')

# Advanced Mode (ê¶Œì¥): JSON + ë²¡í„°DB, ê³ ê¸‰ ê²€ìƒ‰
pm_advanced = ProfileManager(mode='advanced')
```

### 2.2 í”„ë¡œí•„ í…œí”Œë¦¿ ìƒì„±

```python
# ë¹ˆ í”„ë¡œí•„ í…œí”Œë¦¿ ìƒì„±
profile = pm_advanced.create_profile_template()

# í…œí”Œë¦¿ êµ¬ì¡° í™•ì¸
print("í”„ë¡œí•„ ì„¹ì…˜:", list(profile.keys()))
# ì¶œë ¥: ['profile_metadata', 'personal_info', 'education', 'work_experience', 
#        'projects', 'skills', 'certifications', 'awards', 'career_goals', 'interests']
```

### 2.3 ë‹¨ê³„ë³„ ì •ë³´ ì…ë ¥

#### 2.3.1 ê¸°ë³¸ ì •ë³´ ì…ë ¥

```python
profile['personal_info'] = {
    'name': 'ê¹€ë°ì´í„°',
    'email': 'kim.data@example.com',
    'phone': '010-1234-5678',
    'address': 'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬',
    'linkedin': 'https://linkedin.com/in/kimdata',
    'github': 'https://github.com/kimdata',
    'portfolio': 'https://kimdata.github.io',
    'blog': 'https://medium.com/@kimdata'
}
```

#### 2.3.2 í•™ë ¥ ì •ë³´ ì¶”ê°€

```python
profile['education'] = [
    {
        'school': 'ì„œìš¸ëŒ€í•™êµ',
        'degree': 'í•™ì‚¬',
        'major': 'ì»´í“¨í„°ê³µí•™ê³¼',
        'minor': 'í†µê³„í•™ê³¼',  # ì„ íƒì‚¬í•­
        'duration': {'start': '2018-03', 'end': '2022-02'},
        'gpa': {'score': 3.8, 'scale': 4.3},
        'honors': ['magna cum laude', 'í•™ê³¼ ìš°ìˆ˜ìƒ'],
        'relevant_courses': [
            'ë°ì´í„°êµ¬ì¡°ì™€ ì•Œê³ ë¦¬ì¦˜',
            'ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ',
            'ë¨¸ì‹ ëŸ¬ë‹',
            'í†µê³„í•™',
            'ì„ í˜•ëŒ€ìˆ˜í•™',
            'í™•ë¥ ë¡ '
        ],
        'thesis': {  # ì¡¸ì—…ë…¼ë¬¸ (ì„ íƒì‚¬í•­)
            'title': 'ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ê°ì • ë¶„ì„',
            'advisor': 'ê¹€êµìˆ˜'
        }
    }
]
```

#### 2.3.3 ê²½ë ¥ ì •ë³´ ìƒì„¸ ì…ë ¥

```python
profile['work_experience'] = [
    {
        'company': 'ë„¤ì´ë²„',
        'position': 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸',
        'duration': {'start': '2022-03', 'end': '2024-12'},
        'employment_type': 'full-time',
        'department': 'AI Lab',
        'team': 'ì¶”ì²œì‹œìŠ¤í…œíŒ€',
        'responsibilities': [
            'Python pandas, numpyë¥¼ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ì‚¬ìš©ì í–‰ë™ ë°ì´í„° ë¶„ì„',
            'scikit-learn, TensorFlow ê¸°ë°˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ë° ì„±ëŠ¥ ìµœì í™”',
            'A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„, ì‹¤í–‰ ë° í†µê³„ì  ìœ ì˜ì„± ê²€ì •',
            'Tableauë¥¼ í™œìš©í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ êµ¬ì¶• ë° ìš´ì˜',
            'ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ ì•Œê³ ë¦¬ì¦˜ ê°œë°œ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§'
        ],
        'achievements': [
            {
                'description': 'ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ ì •í™•ë„ ê°œì„ ',
                'metrics': 'í´ë¦­ë¥  25% í–¥ìƒ, ì „í™˜ìœ¨ 18% ì¦ê°€',
                'impact': 'ì›”ê°„ í™œì„± ì‚¬ìš©ì 15% ì¦ê°€, ë§¤ì¶œ 12ì–µì› ì¦ëŒ€ ê¸°ì—¬',
                'period': '2023-06 ~ 2024-03'
            },
            {
                'description': 'ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ êµ¬ì¶•',
                'metrics': 'íƒì§€ ì •í™•ë„ 95%, ì‘ë‹µì‹œê°„ 100ms ì´í•˜',
                'impact': 'ì‹œìŠ¤í…œ ì¥ì•  ì˜ˆë°©ìœ¼ë¡œ ì—°ê°„ 5ì–µì› ì†ì‹¤ ë°©ì§€',
                'period': '2023-01 ~ 2023-05'
            }
        ],
        'technologies': [
            'Python', 'pandas', 'numpy', 'scikit-learn', 'TensorFlow',
            'SQL', 'PostgreSQL', 'Redis', 'Apache Kafka', 'Docker',
            'Tableau', 'Jupyter', 'Git', 'AWS (S3, EC2, RDS)'
        ],
        'key_projects': [
            'ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ v2.0',
            'ì‚¬ìš©ì í–‰ë™ ì˜ˆì¸¡ ëª¨ë¸',
            'ì´ìƒ ê±°ë˜ íƒì§€ ì‹œìŠ¤í…œ'
        ]
    }
]
```

#### 2.3.4 í”„ë¡œì íŠ¸ ê²½í—˜ ìƒì„¸ ì…ë ¥

```python
profile['projects'] = [
    {
        'name': 'ì‹¤ì‹œê°„ ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ',
        'description': 'ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ì™€ ì•„ì´í…œ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹¤ì‹œê°„ ê°œì¸í™” ì¶”ì²œ ì—”ì§„ ê°œë°œ',
        'duration': {'start': '2023-06', 'end': '2024-03'},
        'role': 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ (íŒ€ ë¦¬ë”)',
        'team_size': 5,
        'responsibilities': [
            'ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„ ë° êµ¬í˜„',
            'ëŒ€ìš©ëŸ‰ ì‚¬ìš©ì ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•',
            'ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„',
            'ì‹¤ì‹œê°„ ì„œë¹™ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„'
        ],
        'technologies': [
            'Python', 'TensorFlow', 'Apache Kafka', 'Redis',
            'PostgreSQL', 'Docker', 'Kubernetes', 'Apache Airflow'
        ],
        'achievements': [
            'ì¶”ì²œ ì •í™•ë„ 90% ë‹¬ì„± (ê¸°ì¡´ ëŒ€ë¹„ 15% í–¥ìƒ)',
            'ì‹¤ì‹œê°„ ì²˜ë¦¬ ì§€ì—°ì‹œê°„ 100ms ì´í•˜ ë‹¬ì„±',
            'ì¼ì¼ í™œì„± ì‚¬ìš©ì 30% ì¦ê°€',
            'CTR(Click-Through Rate) 40% ê°œì„ '
        ],
        'challenges_solutions': [
            {
                'challenge': 'ëŒ€ìš©ëŸ‰ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬',
                'solution': 'Apache Kafkaì™€ Redisë¥¼ í™œìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ êµ¬ì¶•'
            },
            {
                'challenge': 'ì½œë“œ ìŠ¤íƒ€íŠ¸ ë¬¸ì œ',
                'solution': 'í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§ê³¼ ì»¨í…ì¸  ê¸°ë°˜ í•„í„°ë§ ê²°í•©'
            }
        ],
        'links': {
            'github': 'https://github.com/kimdata/recommendation-system',
            'demo': 'https://demo.recommendation.com',
            'documentation': 'https://docs.recommendation.com'
        },
        'business_impact': 'ì›”ê°„ ë§¤ì¶œ 8ì–µì› ì¦ëŒ€, ì‚¬ìš©ì ë§Œì¡±ë„ 25% í–¥ìƒ'
    }
]
```

#### 2.3.5 ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸ ì •ë³´

```python
profile['skills'] = {
    'programming_languages': [
        {'name': 'Python', 'proficiency': 'expert', 'years': 4, 'projects_count': 15},
        {'name': 'R', 'proficiency': 'advanced', 'years': 2, 'projects_count': 8},
        {'name': 'SQL', 'proficiency': 'expert', 'years': 3, 'projects_count': 20},
        {'name': 'Java', 'proficiency': 'intermediate', 'years': 1, 'projects_count': 3}
    ],
    'frameworks_libraries': {
        'data_analysis': ['pandas', 'numpy', 'scipy', 'statsmodels'],
        'machine_learning': ['scikit-learn', 'TensorFlow', 'PyTorch', 'XGBoost', 'LightGBM'],
        'visualization': ['matplotlib', 'seaborn', 'plotly', 'bokeh'],
        'web_frameworks': ['Flask', 'FastAPI'],
        'others': ['Apache Spark', 'Apache Kafka', 'Apache Airflow']
    },
    'databases': [
        {'name': 'PostgreSQL', 'proficiency': 'expert', 'use_cases': ['OLTP', 'Analytics']},
        {'name': 'MySQL', 'proficiency': 'advanced', 'use_cases': ['Web Applications']},
        {'name': 'MongoDB', 'proficiency': 'intermediate', 'use_cases': ['Document Store']},
        {'name': 'Redis', 'proficiency': 'advanced', 'use_cases': ['Caching', 'Real-time']}
    ],
    'cloud_platforms': [
        {
            'name': 'AWS',
            'proficiency': 'advanced',
            'services': ['S3', 'EC2', 'RDS', 'Lambda', 'SageMaker', 'Kinesis']
        },
        {
            'name': 'Google Cloud Platform',
            'proficiency': 'intermediate', 
            'services': ['BigQuery', 'Cloud ML', 'Dataflow']
        }
    ],
    'tools': {
        'development': ['Git', 'Docker', 'Kubernetes', 'Jenkins'],
        'data_tools': ['Jupyter', 'Apache Spark', 'Apache Kafka', 'Apache Airflow'],
        'visualization': ['Tableau', 'PowerBI', 'Grafana'],
        'monitoring': ['Prometheus', 'ELK Stack']
    },
    'specializations': [
        'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ë° ìµœì í™”',
        'ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„',
        'ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•',
        'A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ ë° ë¶„ì„',
        'ì¶”ì²œ ì‹œìŠ¤í…œ ê°œë°œ',
        'ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡'
    ]
}
```

### 2.4 í”„ë¡œí•„ ì €ì¥ ë° ê´€ë¦¬

```python
# í”„ë¡œí•„ ì €ì¥ (JSON + ë²¡í„°DB ìë™ ë™ê¸°í™”)
profile_path = pm_advanced.save_profile(profile, 'ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v1')
print(f"í”„ë¡œí•„ ì €ì¥ë¨: {profile_path}")

# ì €ì¥ëœ í”„ë¡œí•„ ëª©ë¡ í™•ì¸
profiles = pm_advanced.list_profiles()
print("ì €ì¥ëœ í”„ë¡œí•„ë“¤:", profiles)

# íŠ¹ì • í”„ë¡œí•„ ë¡œë“œ
loaded_profile = pm_advanced.load_profile('ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v1')

# í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì˜ˆì‹œ
loaded_profile['work_experience'].append({
    'company': 'ì¹´ì¹´ì˜¤',
    'position': 'Senior Data Scientist',
    # ... ìƒˆë¡œìš´ ê²½ë ¥ ì •ë³´
})

# ì—…ë°ì´íŠ¸ëœ í”„ë¡œí•„ ì €ì¥ (ë²¡í„°DB ìë™ ì—…ë°ì´íŠ¸)
pm_advanced.save_profile(loaded_profile, 'ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v2')
```

## 3. ìê¸°ì†Œê°œì„œ ì‘ì„± í”„ë¡œì„¸ìŠ¤

### 3.1 ë©”ì¸ í”„ë¡œê·¸ë¨ ì‚¬ìš©ë²•

```bash
# ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰
python main.py
```

ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì˜µì…˜ë“¤ì´ ì œê³µë©ë‹ˆë‹¤:

```
ğŸ“‹ ë°ì´í„° ì…ë ¥ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:
1. ì˜ˆì‹œ ë°ì´í„° ì‚¬ìš© (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
2. ê¸°ì¡´ êµ¬ì¡°í™”ëœ í”„ë¡œí•„ ì‚¬ìš©
3. ìƒˆ êµ¬ì¡°í™”ëœ í”„ë¡œí•„ ìƒì„±
4. ê°„ë‹¨ ì •ë³´ ì…ë ¥

âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •:
- ë¬¸ì„œ ìœ í˜•: resume / cover_letter
- ë¶„ì„ ê¹Šì´: low / medium / high
- ê²€ìƒ‰ ëª¨ë“œ: semantic / keyword / hybrid
```

### 3.2 ì½”ë“œë¥¼ í†µí•œ ì§ì ‘ ì‹¤í–‰

```python
import asyncio
from resumeagents.graph.resume_graph import ResumeAgentsGraph
from resumeagents.default_config import DEFAULT_CONFIG

# ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§•
config = DEFAULT_CONFIG.copy()
config.update({
    'analysis_depth': 'high',           # ë¶„ì„ ê¹Šì´
    'document_type': 'cover_letter',    # ë¬¸ì„œ ìœ í˜•
    'web_search_enabled': True,         # ì›¹ ê²€ìƒ‰ í™œì„±í™”
    'max_debate_rounds': 3,             # í† ë¡  ë¼ìš´ë“œ
    'quality_threshold': 85             # í’ˆì§ˆ ì„ê³„ê°’
})

# ì§€ì› íšŒì‚¬ ë° ì§ë¬´ ì •ë³´
company_name = "ì¹´ì¹´ì˜¤"
job_title = "Senior Data Scientist"
job_description = """
[íšŒì‚¬ ì†Œê°œ]
ì¹´ì¹´ì˜¤ëŠ” ê¸°ìˆ ê³¼ ì‚¬ëŒì„ ì—°ê²°í•˜ì—¬ ë” ë‚˜ì€ ì„¸ìƒì„ ë§Œë“œëŠ” ê¸€ë¡œë²Œ IT ê¸°ì—…ì…ë‹ˆë‹¤.

[ë‹´ë‹¹ ì—…ë¬´]
- ëŒ€ìš©ëŸ‰ ì‚¬ìš©ì ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ, ê²€ì¦ ë° í”„ë¡œë•ì…˜ ë°°í¬
- A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ ë° ì‹¤í—˜ ê²°ê³¼ ë¶„ì„
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë°ì´í„° ê¸°ë°˜ ì†”ë£¨ì…˜ ê°œë°œ

[í•„ìˆ˜ ìš”ê±´]
- ì»´í“¨í„°ê³µí•™, í†µê³„í•™, ìˆ˜í•™ ë“± ê´€ë ¨ í•™ê³¼ í•™ì‚¬ ì´ìƒ
- Python, R ë“±ì„ í™œìš©í•œ ë°ì´í„° ë¶„ì„ ê²½í—˜ 5ë…„ ì´ìƒ
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ë° ìš´ì˜ ê²½í—˜ 3ë…„ ì´ìƒ
- SQLì„ í™œìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê²½í—˜

[ìš°ëŒ€ ì‚¬í•­]
- TensorFlow, PyTorch ë“± ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ í™œìš© ê²½í—˜
- í´ë¼ìš°ë“œ í”Œë«í¼(AWS, GCP) ê¸°ë°˜ ML íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜
- ì¶”ì²œì‹œìŠ¤í…œ, ê²€ìƒ‰ ë“± ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ ê°œë°œ ê²½í—˜
- íŒ€ ë¦¬ë”© ë˜ëŠ” í”„ë¡œì íŠ¸ ë§¤ë‹ˆì§• ê²½í—˜
"""

# ìê¸°ì†Œê°œì„œ ë¬¸í•­ ì„¤ì •
candidate_info = {
    "name": "ê¹€ë°ì´í„°",
    "profile_name": "ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v2",
    "custom_questions": [
        {
            "question": "ì¹´ì¹´ì˜¤ì— ì§€ì›í•œ ë™ê¸°ì™€ ì…ì‚¬ í›„ í¬ë¶€ë¥¼ ê¸°ìˆ í•´ ì£¼ì‹­ì‹œì˜¤.",
            "type": "motivation",
            "char_limit": 1000,
            "char_limit_note": "ê³µë°± í¬í•¨ 1000ì ì´ë‚´"
        },
        {
            "question": "ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ê´€ë ¨ í”„ë¡œì íŠ¸ ì¤‘ ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ ê²½í—˜ê³¼ í•´ê²° ê³¼ì •ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.",
            "type": "data_analysis",
            "char_limit": 1500,
            "char_limit_note": "ê³µë°± í¬í•¨ 1500ì ì´ë‚´"
        },
        {
            "question": "íŒ€ì›Œí¬ë¥¼ ë°œíœ˜í•˜ì—¬ ì„±ê³¼ë¥¼ ë‹¬ì„±í•œ ê²½í—˜ì„ ì„¤ëª…í•˜ê³ , ë³¸ì¸ì˜ ì—­í• ê³¼ ê¸°ì—¬ë„ë¥¼ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.",
            "type": "teamwork",
            "char_limit": 800,
            "char_limit_note": "ê³µë°± í¬í•¨ 800ì ì´ë‚´"
        },
        {
            "question": "ì¹´ì¹´ì˜¤ì˜ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œì„œ ì–´ë–¤ ê°€ì¹˜ë¥¼ ì°½ì¶œí•˜ê³  ì‹¶ì€ì§€ ê¸°ìˆ í•´ ì£¼ì„¸ìš”.",
            "type": "vision",
            "char_limit": 600,
            "char_limit_note": "ê³µë°± í¬í•¨ 600ì ì´ë‚´"
        }
    ]
}

# ResumeAgents ì‹¤í–‰
async def run_resume_agents():
    ra = ResumeAgentsGraph(debug=True, config=config)
    
    final_state, decision = await ra.propagate(
        company_name=company_name,
        job_title=job_title,
        job_description=job_description,
        candidate_info=candidate_info
    )
    
    return final_state, decision

# ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸
final_state, decision = asyncio.run(run_resume_agents())

print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼")
print(f"í’ˆì§ˆ ì ìˆ˜: {decision['quality_score']:.1f}/100")
print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {final_state.output_dir}")
```

## 4. ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥ í™œìš©

### 4.1 ê¸°ë³¸ ê²½í—˜ ê²€ìƒ‰

```python
# ê´€ë ¨ ê²½í—˜ ê²€ìƒ‰
results = pm_advanced.find_relevant_experiences_for_question(
    profile_name='ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v2',
    question='Pythonì„ ì‚¬ìš©í•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ê²½í—˜ì´ ìˆë‚˜ìš”?',
    question_type='data_engineering',
    search_mode='hybrid',
    top_k=5
)

# ê²°ê³¼ ë¶„ì„
for i, result in enumerate(results, 1):
    print(f"\n{i}. ê²€ìƒ‰ ê²°ê³¼:")
    print(f"   íƒ€ì…: {result['type']}")
    print(f"   ê´€ë ¨ë„: {result['relevance_score']:.3f}")
    
    if 'semantic_score' in result:
        print(f"   ì˜ë¯¸ì  ì ìˆ˜: {result['semantic_score']:.3f}")
        print(f"   í‚¤ì›Œë“œ ì ìˆ˜: {result['keyword_score']:.3f}")
    
    print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {result['text'][:100]}...")
    print(f"   ìƒì„¸ ë°ì´í„°: {result['data']}")
```

### 4.2 ë°ì´í„°/AI íŠ¹í™” ì§ˆë¬¸ ìœ í˜•ë³„ ê²€ìƒ‰

```python
# ë‹¤ì–‘í•œ ë°ì´í„°/AI ì§ˆë¬¸ ìœ í˜•ìœ¼ë¡œ ê²€ìƒ‰
search_scenarios = [
    {
        'question': 'TensorFlowë‚˜ PyTorchë¥¼ ì‚¬ìš©í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ ê²½í—˜',
        'type': 'machine_learning'
    },
    {
        'question': 'Apache Sparkë¥¼ í™œìš©í•œ ë¹…ë°ì´í„° ì²˜ë¦¬ í”„ë¡œì íŠ¸',
        'type': 'data_engineering'
    },
    {
        'question': 'Tableauì´ë‚˜ PowerBIë¡œ ë§Œë“  ëŒ€ì‹œë³´ë“œ',
        'type': 'visualization'
    },
    {
        'question': 'ìºê¸€ ê²½ì§„ëŒ€íšŒë‚˜ ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ëŒ€íšŒ ì°¸ì—¬ ê²½í—˜',
        'type': 'kaggle'
    },
    {
        'question': 'A/B í…ŒìŠ¤íŠ¸ë¥¼ ì„¤ê³„í•˜ê³  ë¶„ì„í•œ ê²½í—˜',
        'type': 'ab_testing'
    }
]

for scenario in search_scenarios:
    print(f"\nğŸ” ê²€ìƒ‰: {scenario['question']}")
    print("-" * 60)
    
    results = pm_advanced.find_relevant_experiences_for_question(
        profile_name='ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v2',
        question=scenario['question'],
        question_type=scenario['type'],
        search_mode='hybrid',
        top_k=3
    )
    
    if results:
        best_match = results[0]
        print(f"âœ… ìµœê³  ë§¤ì¹­: [{best_match['type']}] ì ìˆ˜: {best_match['relevance_score']:.3f}")
        print(f"   {best_match['text'][:150]}...")
    else:
        print("âŒ ê´€ë ¨ ê²½í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
```

### 4.3 ê²€ìƒ‰ ëª¨ë“œë³„ ì„±ëŠ¥ ë¹„êµ

```python
def compare_search_modes(question, profile_name):
    """ë‹¤ë¥¸ ê²€ìƒ‰ ëª¨ë“œë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ"""
    modes = ['semantic', 'keyword', 'hybrid']
    
    print(f"ğŸ” ì§ˆë¬¸: {question}")
    print("=" * 80)
    
    for mode in modes:
        results = pm_advanced.find_relevant_experiences_for_question(
            profile_name=profile_name,
            question=question,
            question_type='data_analysis',
            search_mode=mode,
            top_k=3
        )
        
        print(f"\nğŸ“Š {mode.upper()} ëª¨ë“œ ê²°ê³¼:")
        if results:
            for i, result in enumerate(results[:2], 1):
                score_info = f"{result['relevance_score']:.3f}"
                if 'semantic_score' in result:
                    score_info += f" (ì˜ë¯¸:{result['semantic_score']:.3f} + í‚¤ì›Œë“œ:{result['keyword_score']:.3f})"
                
                print(f"   {i}. [{result['type']}] {score_info}")
                print(f"      {result['text'][:100]}...")
        else:
            print("   ê²°ê³¼ ì—†ìŒ")

# ê²€ìƒ‰ ëª¨ë“œ ë¹„êµ ì‹¤í–‰
compare_search_modes(
    "pandasì™€ numpyë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ì „ì²˜ë¦¬ ê²½í—˜",
    "ê¹€ë°ì´í„°_ë°ì´í„°ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸_v2"
)
```

## 5. ê²°ê³¼ ë¶„ì„ ë° í™œìš©

### 5.1 ìƒì„±ëœ ê°€ì´ë“œ ë¶„ì„

```python
# ê²°ê³¼ íŒŒì¼ ë¡œë“œ
import json
from pathlib import Path

# ìµœì‹  ê²°ê³¼ ë””ë ‰í† ë¦¬ ì°¾ê¸°
output_base = Path("outputs")
latest_output = max(output_base.glob("*"), key=lambda x: x.stat().st_mtime)

print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {latest_output}")

# ë¬¸í•­ë³„ ê°€ì´ë“œ ë¶„ì„
with open(latest_output / "question_guides.json", 'r', encoding='utf-8') as f:
    question_guides = json.load(f)

for i, guide in enumerate(question_guides['guides'], 1):
    print(f"\nğŸ“ ë¬¸í•­ {i}: {guide['question']['question']}")
    print(f"   ìœ í˜•: {guide['question']['type']}")
    print(f"   ê¸€ììˆ˜ ì œí•œ: {guide['question'].get('char_limit', 'ì œí•œ ì—†ìŒ')}")
    print(f"   ê°€ì´ë“œ ê¸¸ì´: {len(guide['guide'])}ì")
    print(f"   í•µì‹¬ í¬ì¸íŠ¸: {len(guide.get('key_points', []))}ê°œ")
    
    # í•µì‹¬ í¬ì¸íŠ¸ ì¶œë ¥
    if 'key_points' in guide:
        for j, point in enumerate(guide['key_points'][:3], 1):
            print(f"      {j}. {point}")

# ê²½í—˜ ë§¤ì¹­ ê²°ê³¼ ë¶„ì„
with open(latest_output / "experience_guides.json", 'r', encoding='utf-8') as f:
    experience_guides = json.load(f)

print(f"\nğŸ” ê²½í—˜ ë§¤ì¹­ í†µê³„:")
total_matches = sum(len(guide.get('relevant_experiences', [])) for guide in experience_guides['guides'])
print(f"   ì´ ë§¤ì¹­ëœ ê²½í—˜: {total_matches}ê°œ")

for guide in experience_guides['guides']:
    experiences = guide.get('relevant_experiences', [])
    if experiences:
        avg_score = sum(exp['relevance_score'] for exp in experiences) / len(experiences)
        print(f"   ë¬¸í•­ë³„ í‰ê·  ê´€ë ¨ë„: {avg_score:.3f}")
```

### 5.2 í’ˆì§ˆ ì ìˆ˜ ë¶„ì„

```python
# í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
with open(latest_output / "analysis_results.json", 'r', encoding='utf-8') as f:
    analysis_results = json.load(f)

# í’ˆì§ˆ ì ìˆ˜ ë¶„ì„
quality_scores = analysis_results.get('quality_analysis', {})
print(f"\nğŸ“Š í’ˆì§ˆ ë¶„ì„ ê²°ê³¼:")
print(f"   ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality_scores.get('overall_score', 'N/A')}/100")

# ì„¸ë¶€ í’ˆì§ˆ ì§€í‘œ
quality_metrics = quality_scores.get('detailed_scores', {})
for metric, score in quality_metrics.items():
    print(f"   {metric}: {score}/100")

# ê°œì„  ì œì•ˆì‚¬í•­
improvements = quality_scores.get('improvement_suggestions', [])
if improvements:
    print(f"\nğŸ’¡ ê°œì„  ì œì•ˆì‚¬í•­:")
    for i, suggestion in enumerate(improvements, 1):
        print(f"   {i}. {suggestion}")
```

### 5.3 ê²°ê³¼ ë‚´ë³´ë‚´ê¸°

```python
def export_results_to_markdown(output_dir):
    """ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    
    # íŒŒì¼ë“¤ ë¡œë“œ
    with open(output_dir / "question_guides.json", 'r', encoding='utf-8') as f:
        question_guides = json.load(f)
    
    # ë§ˆí¬ë‹¤ìš´ ìƒì„±
    markdown_content = f"""# ìê¸°ì†Œê°œì„œ ì‘ì„± ê°€ì´ë“œ

> ìƒì„± ì¼ì‹œ: {question_guides['metadata']['created_at']}
> íšŒì‚¬: {question_guides['metadata']['company_name']}
> ì§ë¬´: {question_guides['metadata']['job_title']}

"""
    
    for i, guide in enumerate(question_guides['guides'], 1):
        question = guide['question']
        markdown_content += f"""
## {i}. {question['question']}

**ë¬¸í•­ ìœ í˜•:** {question['type']}  
**ê¸€ììˆ˜ ì œí•œ:** {question.get('char_limit', 'ì œí•œ ì—†ìŒ')}ì

### ğŸ“ ì‘ì„± ê°€ì´ë“œ

{guide['guide']}

### ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸

"""
        
        for j, point in enumerate(guide.get('key_points', []), 1):
            markdown_content += f"{j}. {point}\n"
        
        markdown_content += "\n---\n"
    
    # íŒŒì¼ ì €ì¥
    output_file = output_dir / "ìê¸°ì†Œê°œì„œ_ì‘ì„±_ê°€ì´ë“œ.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"ğŸ“„ ë§ˆí¬ë‹¤ìš´ ê°€ì´ë“œ ìƒì„±: {output_file}")

# ë‚´ë³´ë‚´ê¸° ì‹¤í–‰
export_results_to_markdown(latest_output)
```

## 6. ë¬¸ì œ í•´ê²°

### 6.1 ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### ë¬¸ì œ 1: API í‚¤ ì˜¤ë¥˜
```
Error: OpenAI API key not found
```

**í•´ê²°ë°©ë²•:**
```bash
# í™˜ê²½ë³€ìˆ˜ í™•ì¸
echo $OPENAI_API_KEY

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY="your_api_key_here"

# .env íŒŒì¼ ìƒì„±
echo "OPENAI_API_KEY=your_api_key_here" > .env
```

#### ë¬¸ì œ 2: ë²¡í„°DB ì´ˆê¸°í™” ì‹¤íŒ¨
```
Error: sentence-transformers not found
```

**í•´ê²°ë°©ë²•:**
```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install sentence-transformers faiss-cpu

# ë˜ëŠ” Light ëª¨ë“œ ì‚¬ìš©
pm = ProfileManager(mode='light')
```

#### ë¬¸ì œ 3: ë©”ëª¨ë¦¬ ë¶€ì¡±
```
Error: Out of memory
```

**í•´ê²°ë°©ë²•:**
```python
# ë¶„ì„ ê¹Šì´ë¥¼ ë‚®ì¶¤
config['analysis_depth'] = 'low'

# ë˜ëŠ” Light ëª¨ë“œ ì‚¬ìš©
pm = ProfileManager(mode='light')
```

### 6.2 ì„±ëŠ¥ ìµœì í™” íŒ

#### 6.2.1 ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ
```python
# ìºì‹œ í™œìš©ì„ ìœ„í•´ ë™ì¼í•œ ProfileManager ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
pm = ProfileManager(mode='advanced')

# ê²€ìƒ‰ ë²”ìœ„ ì œí•œ
results = pm.find_relevant_experiences_for_question(
    profile_name='profile_name',
    question='question',
    question_type='specific_type',  # êµ¬ì²´ì ì¸ íƒ€ì… ì§€ì •
    top_k=3,  # í•„ìš”í•œ ë§Œí¼ë§Œ ê²€ìƒ‰
    search_mode='hybrid'
)
```

#### 6.2.2 í”„ë¡œí•„ ê´€ë¦¬ ìµœì í™”
```python
# í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì‹œ ë°°ì¹˜ ì²˜ë¦¬
# ì—¬ëŸ¬ ë³€ê²½ì‚¬í•­ì„ í•œ ë²ˆì— ì €ì¥
profile['work_experience'].append(new_experience_1)
profile['work_experience'].append(new_experience_2)
profile['projects'].append(new_project)

# í•œ ë²ˆì— ì €ì¥ (ë²¡í„°DBë„ í•œ ë²ˆì— ì—…ë°ì´íŠ¸)
pm.save_profile(profile, 'profile_name')
```

### 6.3 ë””ë²„ê¹… ëª¨ë“œ

```python
# ìƒì„¸í•œ ë¡œê·¸ë¥¼ ìœ„í•œ ë””ë²„ê·¸ ëª¨ë“œ
ra = ResumeAgentsGraph(debug=True, config=config)

# ë˜ëŠ” ë¡œê¹… ë ˆë²¨ ì„¤ì •
import logging
logging.basicConfig(level=logging.DEBUG)
```

ì´ ê°€ì´ë“œë¥¼ í†µí•´ ResumeAgentsì˜ ëª¨ë“  ê¸°ëŠ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œê°€ ìˆìœ¼ì‹œë©´ GitHub Issuesë¥¼ í†µí•´ ë¬¸ì˜í•´ ì£¼ì„¸ìš”! 