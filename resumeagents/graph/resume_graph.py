"""
ResumeAgents Graph Implementation with Stage-wise Evaluation and Revision System.
"""

import asyncio
from typing import Dict, Any, Optional
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI

from ..agents.base_agent import AgentState
from ..agents.analysis import CompanyAnalyst, JDAnalyst, MarketAnalyst
from ..agents.matching import CandidateAnalyst, CultureAnalyst, TrendAnalyst
from ..agents.strategy import StrengthResearcher, WeaknessResearcher
from ..agents.production import DocumentWriter, QualityManager
from ..agents.guides import QuestionGuide, ExperienceGuide, WritingGuide
from ..agents.evaluators import (
    AnalysisEvaluator, MatchingEvaluator, StrategyEvaluator, 
    GuideEvaluator, ProductionEvaluator
)
from ..utils import get_model_for_agent, supports_temperature


class ResumeAgentsGraph:
    """Main graph for ResumeAgents framework with stage-wise evaluation."""
    
    def __init__(self, debug: bool = False, config: Optional[Dict[str, Any]] = None):
        self.debug = debug
        self.config = config or {}
        
        # Research depthì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ
        research_depth = self.config.get("research_depth", "MEDIUM")
        quick_model = self.config.get("quick_think_model", "gpt-4o-mini")
        deep_model = self.config.get("deep_think_model", "o4-mini")
        web_search_model = self.config.get("web_search_model", "gpt-4o-mini")
        
        # Initialize LLMs with conditional temperature support
        # Quick Think model (ì›¹ ê²€ìƒ‰ ì§€ì› ëª¨ë¸)
        quick_llm_config = {
            "model": quick_model,
            "max_tokens": self.config.get("max_tokens", 4000)
        }
        if supports_temperature(quick_model):
            quick_llm_config["temperature"] = self.config.get("temperature", 0.7)
        
        self.quick_think_llm = ChatOpenAI(**quick_llm_config)
        
        # Deep Think model (reasoning ëª¨ë¸)
        deep_llm_config = {
            "model": deep_model,
            "max_tokens": self.config.get("max_tokens", 4000)
        }
        if supports_temperature(deep_model):
            deep_llm_config["temperature"] = self.config.get("temperature", 0.7)
        
        self.deep_think_llm = ChatOpenAI(**deep_llm_config)
        
        # Web Search model (ì›¹ ê²€ìƒ‰ ì „ìš© ëª¨ë¸)
        web_search_llm_config = {
            "model": web_search_model,
            "max_tokens": self.config.get("web_search_max_tokens", 3000)
        }
        if supports_temperature(web_search_model):
            web_search_llm_config["temperature"] = self.config.get("temperature", 0.7)
        
        self.web_search_llm = ChatOpenAI(**web_search_llm_config)
        
        # Research depth ì •ë³´ ì¶œë ¥
        if self.debug:
            print(f"[DEBUG] Research Depth: {research_depth}")
            print(f"[DEBUG] Analysis Depth: {self.config.get('analysis_depth', 'balanced')}")
            print(f"[DEBUG] Web Search: {'Enabled' if self.config.get('web_search_enabled', True) else 'Disabled'}")
            print(f"[DEBUG] Quality Threshold: {self.config.get('quality_threshold', 0.8)}")
            print(f"[DEBUG] Max Tokens: {self.config.get('max_tokens', 4000)}")
            print(f"[DEBUG] Max Revision Rounds: {self.config.get('max_revision_rounds', 2)}")
        
        # Initialize agents and evaluators
        self.agents = self._initialize_agents()
        self.evaluators = self._initialize_evaluators()
        
        # Build graph
        self.graph = self._build_graph()
    
    def log(self, message: str):
        """Log message if debug is enabled."""
        if self.debug:
            print(f"[GRAPH] {message}")
    
    def _initialize_evaluators(self) -> Dict[str, Any]:
        """í‰ê°€ìë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        from ..utils import get_research_depth_config
        
        # Research depth ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        research_config = get_research_depth_config(self.config.get("research_depth", "MEDIUM"))
        
        # í‰ê°€ìš© ëª¨ë¸ ì„¤ì • (depthë³„)
        eval_llm_config = {
            "model": research_config.get("evaluator_model", "gpt-4o-mini"),
            "max_tokens": research_config.get("evaluator_max_tokens", 2000)
        }
        
        # Temperature ì§€ì› ì—¬ë¶€ í™•ì¸ í›„ ì¶”ê°€
        evaluator_model = research_config.get("evaluator_model", "gpt-4o-mini")
        if supports_temperature(evaluator_model):
            eval_llm_config["temperature"] = research_config.get("evaluator_temperature", 0.3)
        
        eval_llm = ChatOpenAI(**eval_llm_config)
        
        if self.debug:
            print(f"[DEBUG] Evaluator Model: {evaluator_model}")
            print(f"[DEBUG] Evaluator Max Tokens: {research_config.get('evaluator_max_tokens', 2000)}")
            print(f"[DEBUG] Evaluator Temperature: {research_config.get('evaluator_temperature', 0.3)}")
        
        return {
            "analysis_evaluator": AnalysisEvaluator(llm=eval_llm, config=self.config),
            "matching_evaluator": MatchingEvaluator(llm=eval_llm, config=self.config),
            "strategy_evaluator": StrategyEvaluator(llm=eval_llm, config=self.config),
            "guide_evaluator": GuideEvaluator(llm=eval_llm, config=self.config),
            "production_evaluator": ProductionEvaluator(llm=eval_llm, config=self.config)
        }
    
    def _initialize_agents(self) -> Dict[str, Any]:
        """Initialize all agents with appropriate models for each stage."""
        from ..utils import get_research_depth_config
        
        # Get research depth configuration
        research_config = get_research_depth_config(self.config.get("research_depth", "MEDIUM"))
        
        agents = {}
        
        # Analysis agents
        agents["company_analyst"] = CompanyAnalyst(
            llm=self._get_llm_for_agent("company_analysis", research_config),
            config=self.config
        )
        agents["jd_analyst"] = JDAnalyst(
            llm=self._get_llm_for_agent("jd_analysis", research_config),
            config=self.config
        )
        agents["market_analyst"] = MarketAnalyst(
            llm=self._get_llm_for_agent("market_analysis", research_config),
            config=self.config
        )
        
        # Evaluation agents
        agents["candidate_analyst"] = CandidateAnalyst(
            llm=self._get_llm_for_agent("candidate_analysis", research_config),
            config=self.config
        )
        agents["culture_analyst"] = CultureAnalyst(
            llm=self._get_llm_for_agent("culture_analysis", research_config),
            config=self.config
        )
        agents["trend_analyst"] = TrendAnalyst(
            llm=self._get_llm_for_agent("trend_analysis", research_config),
            config=self.config
        )
        
        # Research agents
        agents["strength_researcher"] = StrengthResearcher(
            llm=self._get_llm_for_agent("strength_research", research_config),
            config=self.config
        )
        agents["weakness_researcher"] = WeaknessResearcher(
            llm=self._get_llm_for_agent("weakness_research", research_config),
            config=self.config
        )
        
        # Guide agents
        agents["question_guide"] = QuestionGuide(
            llm=self._get_llm_for_agent("question_guide", research_config),
            config=self.config
        )
        agents["experience_guide"] = ExperienceGuide(
            llm=self._get_llm_for_agent("experience_guide", research_config),
            config=self.config
        )
        agents["writing_guide"] = WritingGuide(
            llm=self._get_llm_for_agent("writing_guide", research_config),
            config=self.config
        )
        
        # Production agents
        agents["document_writer"] = DocumentWriter(
            llm=self._get_llm_for_agent("document_writing", research_config),
            config=self.config
        )
        agents["quality_manager"] = QualityManager(
            llm=self._get_llm_for_agent("quality_management", research_config),
            config=self.config
        )
        
        return agents
    
    def _get_llm_for_agent(self, agent_name: str, research_config: dict) -> ChatOpenAI:
        """Get appropriate LLM for specific agent based on research depth configuration."""
        from ..utils import get_model_for_agent

        # ì—ì´ì „íŠ¸ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
        model_name = get_model_for_agent(agent_name, research_config)

        # LLM ì„¤ì • êµ¬ì„±
        llm_config = {
            "model": model_name,
            "max_tokens": research_config.get("max_tokens", 4000)
        }

        # Temperature ì§€ì› ì—¬ë¶€ í™•ì¸ í›„ ì¶”ê°€
        if supports_temperature(model_name):
            llm_config["temperature"] = self.config.get("temperature", 0.7)

        if self.debug:
            print(f"[DEBUG] {agent_name} -> {model_name}")

        return ChatOpenAI(**llm_config)
    
    def _create_stage_evaluation_node(self, stage_name: str, team_name: str, evaluator_key: str):
        """íŒ€ë³„ í‰ê°€ ë…¸ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        async def team_evaluation(state: AgentState) -> AgentState:
            """íŠ¹ì • íŒ€ì˜ ê²°ê³¼ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
            if self.debug:
                print(f"Running {stage_name}_evaluation...")

            # í•´ë‹¹ íŒ€ì˜ ëª¨ë“  ê²°ê³¼ë¥¼ ìˆ˜ì§‘
            team_agents = self._get_team_agents(team_name)
            team_results = {}
            
            for agent_key in team_agents:
                agent_result_key = agent_key.replace("_analyst", "_analysis").replace("_researcher", "_research")
                if hasattr(state, 'analysis_results') and agent_result_key in state.analysis_results:
                    team_results[agent_result_key] = state.analysis_results[agent_result_key]

            if not team_results:
                self.log(f"âš ï¸ {stage_name} íŒ€ ê²°ê³¼ ì—†ìŒ - í‰ê°€ ìŠ¤í‚µ")
                return state

            # í‰ê°€ì ì‹¤í–‰ (íŒ€ ì „ì²´ ê²°ê³¼ë¥¼ í‰ê°€)
            evaluator = self.evaluators[evaluator_key]
            needs_revision, feedback, scores = await evaluator.evaluate_stage(
                state, team_results, team_name
            )

            # ë¦¬ë¹„ì „ì´ í•„ìš”í•œ ê²½ìš° í”¼ë“œë°± ì €ì¥
            if needs_revision:
                revision_key = f"{team_name}_revision_feedback"
                state.analysis_results[revision_key] = {
                    "feedback": feedback,
                    "scores": scores,
                    "needs_revision": True,
                    "evaluator": evaluator.name,
                    "timestamp": "2024-01-15"
                }

                # ë¦¬ë¹„ì „ ì¹´ìš´í„° ì´ˆê¸°í™”
                revision_count_key = f"{team_name}_revision_count"
                if revision_count_key not in state.analysis_results:
                    state.analysis_results[revision_count_key] = 0
                    
                self.log(f"âŒ {stage_name} íŒ€ í‰ê°€ ë¯¸ë‹¬ - ë¦¬ë¹„ì „ í•„ìš”")
            else:
                self.log(f"âœ… {stage_name} íŒ€ í‰ê°€ í†µê³¼")

            return state

        return team_evaluation
    
    def _create_stage_revision_node(self, team_name: str):
        """íŒ€ë³„ ë¦¬ë¹„ì „ ë…¸ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        async def team_revision(state: AgentState) -> AgentState:
            """íŠ¹ì • íŒ€ì„ ë¦¬ë¹„ì „í•©ë‹ˆë‹¤."""
            if self.debug:
                print(f"Running {team_name}_revision...")

            # ë¦¬ë¹„ì „ í”¼ë“œë°± ê°€ì ¸ì˜¤ê¸°
            revision_key = f"{team_name}_revision_feedback"
            revision_data = state.analysis_results.get(revision_key, {})
            feedback = revision_data.get("feedback", [])

            # ë¦¬ë¹„ì „ ì¹´ìš´í„° ì¦ê°€
            revision_count_key = f"{team_name}_revision_count"
            current_count = state.analysis_results.get(revision_count_key, 0)
            state.analysis_results[revision_count_key] = current_count + 1

            # íŒ€ë³„ ì—ì´ì „íŠ¸ ë§¤í•‘
            team_agents = self._get_team_agents(team_name)
            
            # íŒ€ì˜ ëª¨ë“  ì—ì´ì „íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰
            for agent_key in team_agents:
                if agent_key in self.agents:
                    agent = self.agents[agent_key]
                    
                    # ì—ì´ì „íŠ¸ì˜ analyze ë©”ì„œë“œì— í”¼ë“œë°± ì „ë‹¬
                    original_analyze = agent.analyze

                    async def analyze_with_feedback(state_param):
                        # í”¼ë“œë°±ì„ stateì— ì„ì‹œ ì €ì¥
                        if feedback:
                            state_param.revision_feedback = feedback
                            state_param.is_revision = True
                            state_param.revision_count = current_count + 1

                        return await original_analyze(state_param)

                    agent.analyze = analyze_with_feedback
                    result_state = await agent.analyze(state)
                    agent.analyze = original_analyze  # ì›ë˜ ë©”ì„œë“œë¡œ ë³µì›
                    
                    state = result_state

            self.log(f"ğŸ”„ {team_name} ë¦¬ë¹„ì „ ì™„ë£Œ (ì‹œë„ {current_count + 1})")
            return state

        return team_revision
    
    def _get_team_agents(self, team_name: str) -> list:
        """íŒ€ë³„ ì—ì´ì „íŠ¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        team_mapping = {
            "analysis_team": ["company_analyst", "market_analyst", "jd_analyst"],
            "matching_team": ["candidate_analyst", "culture_analyst", "trend_analyst"],
            "strategy_team": ["strength_researcher", "weakness_researcher"],
            "guide_team": ["question_guide", "experience_guide", "writing_guide"],
            "production_team": ["document_writer", "quality_manager"]
        }
        return team_mapping.get(team_name, [])

    def _should_revise_stage(self, team_name: str):
        """íŒ€ë³„ ë¦¬ë¹„ì „ í•„ìš”ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤."""
        def should_revise(state: AgentState) -> str:
            revision_key = f"{team_name}_revision_feedback"
            revision_data = state.analysis_results.get(revision_key, {})
            needs_revision = revision_data.get("needs_revision", False)

            # ìµœëŒ€ ë¦¬ë¹„ì „ íšŸìˆ˜ í™•ì¸
            revision_count_key = f"{team_name}_revision_count"
            current_count = state.analysis_results.get(revision_count_key, 0)
            max_revisions = self.config.get("max_revision_rounds", 2)

            if needs_revision and current_count < max_revisions:
                return "revise"
            else:
                return "continue"

        return should_revise
    
    def _build_graph(self) -> StateGraph:
        """ì „ëµ ë¬¸ì„œì— ë”°ë¥¸ ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        graph = StateGraph(AgentState)
        
        # === Phase 1: Analysis Team (External Information Analysis) ===
        # Company â†’ Market â†’ JD ìˆœì„œë¡œ ì»¨í…ìŠ¤íŠ¸ ëˆ„ì 
        graph.add_node("company_analysis", self.agents["company_analyst"].analyze)
        graph.add_node("market_analysis", self.agents["market_analyst"].analyze)
        graph.add_node("jd_analysis", self.agents["jd_analyst"].analyze)
        
        # Analysis Phase Evaluation
        graph.add_node("analysis_evaluation", self._create_stage_evaluation_node("analysis", "analysis_team", "analysis_evaluator"))
        graph.add_node("analysis_revision", self._create_stage_revision_node("analysis_team"))
        
        # === Phase 2: Matching Team (Candidate-Company Matching) ===
        graph.add_node("candidate_analysis", self.agents["candidate_analyst"].analyze)
        graph.add_node("culture_analysis", self.agents["culture_analyst"].analyze)
        graph.add_node("trend_analysis", self.agents["trend_analyst"].analyze)
        
        # Matching Phase Evaluation
        graph.add_node("matching_evaluation", self._create_stage_evaluation_node("matching", "matching_team", "matching_evaluator"))
        graph.add_node("matching_revision", self._create_stage_revision_node("matching_team"))
        
        # === Phase 3: Strategy Team (Strategic Positioning) ===
        graph.add_node("strength_research", self.agents["strength_researcher"].analyze)
        graph.add_node("weakness_research", self.agents["weakness_researcher"].analyze)
        
        # Strategy Phase Evaluation
        graph.add_node("strategy_evaluation", self._create_stage_evaluation_node("strategy", "strategy_team", "strategy_evaluator"))
        graph.add_node("strategy_revision", self._create_stage_revision_node("strategy_team"))
        
        # === Phase 4: Guide Team (Writing Guidance) ===
        graph.add_node("question_guide", self.agents["question_guide"].analyze)
        graph.add_node("experience_guide", self.agents["experience_guide"].analyze)
        graph.add_node("writing_guide", self.agents["writing_guide"].analyze)
        
        # Guide Phase Evaluation
        graph.add_node("guide_evaluation", self._create_stage_evaluation_node("guide", "guide_team", "guide_evaluator"))
        graph.add_node("guide_revision", self._create_stage_revision_node("guide_team"))
        
        # === Phase 5: Production Team (Document Creation) ===
        graph.add_node("document_writing", self.agents["document_writer"].analyze)
        graph.add_node("quality_management", self.agents["quality_manager"].analyze)
        
        # Production Phase Evaluation
        graph.add_node("production_evaluation", self._create_stage_evaluation_node("production", "production_team", "production_evaluator"))
        graph.add_node("production_revision", self._create_stage_revision_node("production_team"))
        
        # === ì›Œí¬í”Œë¡œìš° ì—°ê²° ===
        # Phase 1: Analysis Team (ìˆœì°¨ ì‹¤í–‰ + í‰ê°€)
        graph.add_edge("company_analysis", "market_analysis")
        graph.add_edge("market_analysis", "jd_analysis")
        graph.add_edge("jd_analysis", "analysis_evaluation")
        
        # Analysis evaluation with revision loop
        graph.add_conditional_edges(
            "analysis_evaluation",
            self._should_revise_stage("analysis_team"),
            {
                "revise": "analysis_revision",
                "continue": "candidate_analysis"
            }
        )
        graph.add_edge("analysis_revision", "analysis_evaluation")
        
        # Phase 2: Matching Team (ìˆœì°¨ ì‹¤í–‰ + í‰ê°€)
        graph.add_edge("candidate_analysis", "culture_analysis")
        graph.add_edge("culture_analysis", "trend_analysis")
        graph.add_edge("trend_analysis", "matching_evaluation")
        
        # Matching evaluation with revision loop
        graph.add_conditional_edges(
            "matching_evaluation",
            self._should_revise_stage("matching_team"),
            {
                "revise": "matching_revision",
                "continue": "strength_research"
            }
        )
        graph.add_edge("matching_revision", "matching_evaluation")
        
        # Phase 3: Strategy Team (ìˆœì°¨ ì‹¤í–‰ + í‰ê°€)
        graph.add_edge("strength_research", "weakness_research")
        graph.add_edge("weakness_research", "strategy_evaluation")
        
        # Strategy evaluation with revision loop
        graph.add_conditional_edges(
            "strategy_evaluation",
            self._should_revise_stage("strategy_team"),
            {
                "revise": "strategy_revision",
                "continue": "question_guide"
            }
        )
        graph.add_edge("strategy_revision", "strategy_evaluation")
        
        # Phase 4: Guide Team (ìˆœì°¨ ì‹¤í–‰ + í‰ê°€)
        graph.add_edge("question_guide", "experience_guide")
        graph.add_edge("experience_guide", "writing_guide")
        graph.add_edge("writing_guide", "guide_evaluation")
        
        # Guide evaluation with revision loop
        graph.add_conditional_edges(
            "guide_evaluation",
            self._should_revise_stage("guide_team"),
            {
                "revise": "guide_revision",
                "continue": "workflow_decision"
            }
        )
        graph.add_edge("guide_revision", "guide_evaluation")
        
        # === User Selection Workflow Decision ===
        graph.add_node("workflow_decision", lambda state: state)  # Pass-through node
        graph.add_conditional_edges(
            "workflow_decision",
            self._decide_workflow,
            {
                "guide_only": END,
                "create_document": "document_writing"
            }
        )
        
        # Phase 5: Production Team (ìˆœì°¨ ì‹¤í–‰ + í‰ê°€)
        graph.add_edge("document_writing", "quality_management")
        graph.add_edge("quality_management", "production_evaluation")
        
        # Production evaluation with revision loop
        graph.add_conditional_edges(
            "production_evaluation",
            self._should_revise_stage("production_team"),
            {
                "revise": "production_revision",
                "continue": END
            }
        )
        graph.add_edge("production_revision", "production_evaluation")
        
        # ì‹œì‘ì  ì„¤ì •
        graph.set_entry_point("company_analysis")
        
        return graph.compile()
    
    def _decide_workflow(self, state: AgentState) -> str:
        """ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ì›Œí¬í”Œë¡œìš°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        workflow_type = self.config.get("workflow_type", "both")
        
        if workflow_type == "guide_only":
            self.log("ğŸ“‹ Guide-Only ì›Œí¬í”Œë¡œìš° ì„ íƒ")
            return "guide_only"
        else:
            self.log("ğŸ“„ Document Creation ì›Œí¬í”Œë¡œìš° ì„ íƒ")
            return "create_document"
    
    async def run(self, initial_state: AgentState) -> AgentState:
        """ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        self.log("ğŸš€ ResumeAgents ì›Œí¬í”Œë¡œìš° ì‹œì‘")
        
        try:
            result = await self.graph.ainvoke(initial_state)
            self.log("âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            return result
        except Exception as e:
            self.log(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            raise 