#!/usr/bin/env python3
"""
AI ê¸°ë°˜ ì´ë ¥ì„œ ìë™ ë³€í™˜ ë„êµ¬ - ResumeAgents í†µí•© ë²„ì „

ResumeAgentsì˜ ì„¤ì • ì‹œìŠ¤í…œê³¼ ëª¨ë¸ ë¶„ë¥˜ë¥¼ í™œìš©í•˜ì—¬ ê¸°ì¡´ ì´ë ¥ì„œë¥¼ JSON í”„ë¡œí•„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
DEVELOPMENT_STRATEGY.mdì˜ ì•„í‚¤í…ì²˜ë¥¼ ì¤€ìˆ˜í•˜ë©° ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì™„ì „ í†µí•©ë©ë‹ˆë‹¤.

ì‚¬ìš© ë°©ë²•:
1. python -m resumeagents.utils.ai_resume_converter ì‹¤í–‰
2. ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œ ì…ë ¥
3. ì—°êµ¬ ê¹Šì´ ì„ íƒ (LOW/MEDIUM/HIGH)
4. AIê°€ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ JSON í”„ë¡œí•„ ìƒì„±
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

# ResumeAgents ëª¨ë“ˆ import
from ..default_config import DEFAULT_CONFIG, get_depth_config
from ..utils import get_model_for_agent, get_research_depth_config
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class AIResumeConverter:
    """AI ê¸°ë°˜ ì´ë ¥ì„œ ë³€í™˜ê¸° - ResumeAgents í†µí•© ë²„ì „"""
    
    def __init__(self, research_depth: str = "MEDIUM"):
        """
        ì´ˆê¸°í™”
        
        Args:
            research_depth: ì—°êµ¬ ê¹Šì´ (LOW/MEDIUM/HIGH)
        """
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=your_key_here ë¥¼ ì¶”ê°€í•˜ì„¸ìš”")
            sys.exit(1)
        
        # ResumeAgents ì„¤ì • ì‹œìŠ¤í…œ í™œìš©
        self.research_depth = research_depth.upper()
        self.config = DEFAULT_CONFIG.copy()
        self.config["research_depth"] = self.research_depth
        
        # Depthë³„ ì„¤ì • ë¡œë“œ
        depth_config = get_depth_config(self.research_depth)
        self.config.update(depth_config)
        
        print(f"ğŸ”§ ResumeAgents ì„¤ì • ë¡œë“œ ì™„ë£Œ:")
        print(f"   ì—°êµ¬ ê¹Šì´: {self.research_depth}")
        print(f"   í’ˆì§ˆ ì„ê³„ê°’: {self.config['quality_threshold']}")
        print(f"   ìµœëŒ€ í† í°: {self.config['max_tokens']}")
        
        # ë³€í™˜ ì‘ì—…ì— ì í•©í•œ ëª¨ë¸ ì„ íƒ (Quick Think ëª¨ë¸ ì‚¬ìš©)
        conversion_model = get_model_for_agent("resume_conversion", self.config)
        
        # LLM ì´ˆê¸°í™” (ResumeAgents ë°©ì‹)
        llm_config = {
            "model": conversion_model,
            "temperature": 0.1,  # ì¼ê´€ëœ ë¶„ì„ì„ ìœ„í•´ ë‚®ì€ temperature
            "max_tokens": self.config.get("max_tokens", 4000)
        }
        
        self.llm = ChatOpenAI(**llm_config)
        
        print(f"âœ… AI ë³€í™˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {conversion_model})")
    
    def read_resume_file(self, file_path: str) -> str:
        """ì´ë ¥ì„œ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        try:
            # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬
            if file_path.lower().endswith('.pdf'):
                return self._extract_text_from_pdf(file_path)
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì²˜ë¦¬ (ë‹¤ì¤‘ ì¸ì½”ë”© ì§€ì›)
                encodings = ['utf-8', 'cp949', 'latin-1', 'euc-kr']
                
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            content = f.read()
                        
                        if not content.strip():
                            raise ValueError("íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                        
                        print(f"âœ… íŒŒì¼ ì½ê¸° ì„±ê³µ (ì¸ì½”ë”©: {encoding})")
                        return content
                        
                    except UnicodeDecodeError:
                        continue
                
                raise ValueError("ì§€ì›ë˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            raise
    
    def _extract_text_from_pdf(self, pdf_path: str) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            import PyPDF2
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() + "\n"
                return text
        except ImportError:
            print("âš ï¸  PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ PyPDF2ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:")
            print("   pip install PyPDF2")
            print("ğŸ’¡ ë˜ëŠ” PDFë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ .txt íŒŒì¼ë¡œ ì €ì¥í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”")
            return ""
        except Exception as e:
            print(f"âŒ PDF ì½ê¸° ì˜¤ë¥˜: {e}")
            return ""
    
    def create_conversion_prompt(self, resume_text: str) -> str:
        """
        ResumeAgents í”„ë¡œí•„ í˜•ì‹ì— ë§ëŠ” ë³€í™˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        DEVELOPMENT_STRATEGY.mdì˜ í”„ë¡œí•„ êµ¬ì¡°ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.
        """
        return f"""
ë‹¤ìŒ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ResumeAgents í”„ë¡œí•„ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

=== ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ===
{resume_text}
=== ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ë ===

ResumeAgents ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•˜ëŠ” ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ì •í™•íˆ ë³€í™˜í•´ì£¼ì„¸ìš”:

{{
  "personal_info": {{
    "name": "ì´ë¦„ (í•„ìˆ˜)",
    "email": "ì´ë©”ì¼",
    "phone": "ì „í™”ë²ˆí˜¸",
    "location": "ê±°ì£¼ì§€ì—­"
  }},
  "education": [
    {{
      "degree": "í•™ìœ„ (í•™ì‚¬/ì„ì‚¬/ë°•ì‚¬)",
      "major": "ì „ê³µ",
      "university": "í•™êµëª…",
      "graduation_year": "ì¡¸ì—…ë…„ë„",
      "gpa": "í•™ì  (ì„ íƒì‚¬í•­)",
      "relevant_courses": ["ê´€ë ¨ ê³¼ëª©ë“¤"],
      "honors": ["ìˆ˜ìƒë‚´ì—­ë“¤"]
    }}
  ],
  "work_experience": [
    {{
      "company": "íšŒì‚¬ëª…",
      "position": "ì§ì±…",
      "duration": {{
        "start": "YYYY-MM í˜•ì‹",
        "end": "YYYY-MM í˜•ì‹ ë˜ëŠ” current"
      }},
      "department": "ë¶€ì„œëª…",
      "responsibilities": ["ì£¼ìš” ì—…ë¬´ë“¤"],
      "achievements": [
        {{
          "description": "ì„±ê³¼ ì„¤ëª…",
          "metrics": "ì •ëŸ‰ì  ì§€í‘œ (ìˆ«ì í¬í•¨)",
          "impact": "ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸"
        }}
      ],
      "technologies": ["ì‚¬ìš© ê¸°ìˆ ë“¤"],
      "team_size": "íŒ€ ê·œëª¨",
      "key_projects": ["í•µì‹¬ í”„ë¡œì íŠ¸ë“¤"]
    }}
  ],
  "projects": [
    {{
      "name": "í”„ë¡œì íŠ¸ëª…",
      "type": "ê°œì¸/íŒ€/íšŒì‚¬ í”„ë¡œì íŠ¸",
      "duration": {{
        "start": "YYYY-MM",
        "end": "YYYY-MM"
      }},
      "description": "í”„ë¡œì íŠ¸ ìƒì„¸ ì„¤ëª…",
      "role": "ë³¸ì¸ ì—­í• ê³¼ ì±…ì„",
      "technologies": ["ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ"],
      "achievements": "êµ¬ì²´ì  ì„±ê³¼ì™€ ê²°ê³¼",
      "github_url": "GitHub ì €ì¥ì†Œ URL",
      "demo_url": "ë°ëª¨/ë°°í¬ URL",
      "team_size": "íŒ€ ê·œëª¨"
    }}
  ],
  "skills": {{
    "programming_languages": ["í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë“¤"],
    "frameworks": ["í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤"],
    "databases": ["ë°ì´í„°ë² ì´ìŠ¤ë“¤"],
    "tools": ["ê°œë°œ/í˜‘ì—… ë„êµ¬ë“¤"],
    "cloud_platforms": ["í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ë“¤"]
  }},
  "certifications": [
    {{
      "name": "ìê²©ì¦ëª…",
      "issuer": "ë°œê¸‰ê¸°ê´€",
      "date": "ì·¨ë“ì¼ (YYYY-MM)",
      "expiry": "ë§Œë£Œì¼ (ìˆë‹¤ë©´)",
      "score": "ì ìˆ˜ (ìˆë‹¤ë©´)"
    }}
  ],
  "awards": [
    {{
      "name": "ìˆ˜ìƒëª…",
      "issuer": "ìˆ˜ì—¬ê¸°ê´€",
      "date": "ìˆ˜ìƒì¼ (YYYY-MM)",
      "description": "ìˆ˜ìƒ ë‚´ìš©ê³¼ ì˜ë¯¸"
    }}
  ],
  "interests": ["ê´€ì‹¬ ë¶„ì•¼ë“¤"],
  "career_goals": {{
    "short_term": "ë‹¨ê¸° ëª©í‘œ (1-2ë…„)",
    "long_term": "ì¥ê¸° ëª©í‘œ (3-5ë…„)",
    "target_companies": ["ê´€ì‹¬ íšŒì‚¬ë“¤"],
    "preferred_roles": ["í¬ë§ ì§ë¬´ë“¤"]
  }},
  "portfolio_links": {{
    "github": "GitHub í”„ë¡œí•„ URL",
    "blog": "ê¸°ìˆ  ë¸”ë¡œê·¸ URL",
    "linkedin": "LinkedIn í”„ë¡œí•„ URL",
    "portfolio": "í¬íŠ¸í´ë¦¬ì˜¤ ì‚¬ì´íŠ¸ URL"
  }}
}}

ì¤‘ìš”í•œ ë³€í™˜ ì§€ì¹¨:
1. **ì •í™•ì„±**: í…ìŠ¤íŠ¸ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì •ë³´ëŠ” ë¹ˆ ë¬¸ìì—´ "" ë˜ëŠ” ë¹ˆ ë°°ì—´ []ë¡œ ì„¤ì •
2. **ë‚ ì§œ í˜•ì‹**: ëª¨ë“  ë‚ ì§œëŠ” YYYY-MM í˜•ì‹ìœ¼ë¡œ í†µì¼ (ì˜ˆ: 2023-03)
3. **ê¸°ìˆ  ë¶„ë¥˜**: ê¸°ìˆ ë“¤ì„ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ì •í™•íˆ ë¶„ë¥˜
4. **ì„±ê³¼ êµ¬ì¡°í™”**: achievementsëŠ” ë°˜ë“œì‹œ description, metrics, impact êµ¬ì¡°ë¡œ ì‘ì„±
5. **ì •ëŸ‰ì  ì§€í‘œ**: ìˆ«ìê°€ ìˆëŠ” ì„±ê³¼ëŠ” metricsì— ëª…í™•íˆ ê¸°ë¡
6. **JSON ìœ íš¨ì„±**: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
7. **í•œêµ­ì–´ ì‚¬ìš©**: ëª¨ë“  í…ìŠ¤íŠ¸ ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±

ì—°êµ¬ ê¹Šì´: {self.research_depth}
í’ˆì§ˆ ê¸°ì¤€: {self.config['quality_threshold']}

JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
"""
    
    async def convert_resume_to_profile(self, resume_text: str) -> Dict[str, Any]:
        """ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ResumeAgents í”„ë¡œí•„ JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        print(f"ğŸ¤– AIê°€ ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ê¹Šì´: {self.research_depth})")
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.create_conversion_prompt(resume_text)
        
        # AI í˜¸ì¶œ (ResumeAgents ë°©ì‹)
        messages = [
            SystemMessage(content="""ë‹¹ì‹ ì€ ResumeAgents ì‹œìŠ¤í…œì˜ ì´ë ¥ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë¶„ì„í•˜ì—¬ ResumeAgents í”„ë¡œí•„ í˜•ì‹ì˜ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
íŠ¹íˆ ì •ëŸ‰ì  ì„±ê³¼, ê¸°ìˆ  ìŠ¤íƒ ë¶„ë¥˜, ê²½í—˜ì˜ ì„íŒ©íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."""),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.llm.ainvoke(messages)
            json_text = response.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                profile = json.loads(json_text)
                
                # ResumeAgents ë©”íƒ€ë°ì´í„° ì¶”ê°€
                profile.update({
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                    "version": "2.0",
                    "conversion_method": "AI_automated",
                    "research_depth": self.research_depth,
                    "vectordb_synced": False
                })
                
                return profile
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                print(f"AI ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {json_text[:300]}...")
                
                # JSON ìˆ˜ì • ì‹œë„
                return self._fix_json_response(json_text)
                
        except Exception as e:
            print(f"âŒ AI ë³€í™˜ ì˜¤ë¥˜: {e}")
            raise
    
    def _fix_json_response(self, json_text: str) -> Dict[str, Any]:
        """ì˜ëª»ëœ JSON ì‘ë‹µì„ ìˆ˜ì • ì‹œë„í•©ë‹ˆë‹¤."""
        print("ğŸ”§ JSON í˜•ì‹ì„ ìˆ˜ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        # ì¼ë°˜ì ì¸ JSON ì˜¤ë¥˜ ìˆ˜ì •
        json_text = json_text.strip()
        
        # ì½”ë“œ ë¸”ë¡ ë§ˆí¬ë‹¤ìš´ ì œê±°
        if json_text.startswith("```"):
            lines = json_text.split('\n')
            json_text = '\n'.join(lines[1:-1])
        
        # ë‹¤ì‹œ íŒŒì‹± ì‹œë„
        try:
            return json.loads(json_text)
        except:
            # ResumeAgents í˜¸í™˜ ë¹ˆ í…œí”Œë¦¿ ë°˜í™˜
            print("âš ï¸  ìë™ ë³€í™˜ ì‹¤íŒ¨. ResumeAgents í˜¸í™˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._create_resumeagents_template()
    
    def _create_resumeagents_template(self) -> Dict[str, Any]:
        """ResumeAgents í˜¸í™˜ ë¹ˆ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        from .profile_manager import ProfileManager
        
        # ProfileManagerë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œì¤€ í…œí”Œë¦¿ ìƒì„±
        pm = ProfileManager()
        template = pm.create_profile_template()
        
        # ë³€í™˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        template.update({
            "conversion_method": "template_fallback",
            "research_depth": self.research_depth
        })
        
        return template
    
    def save_profile(self, profile: Dict[str, Any], filename: str) -> str:
        """í”„ë¡œí•„ì„ ResumeAgents profiles í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤."""
        # ResumeAgents í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
        current_dir = Path(__file__).parent
        project_root = current_dir.parent.parent
        profiles_dir = project_root / "profiles"
        
        profiles_dir.mkdir(exist_ok=True)
        filepath = profiles_dir / f"{filename}.json"
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)
        
        return str(filepath)
    
    def print_conversion_summary(self, profile: Dict[str, Any]):
        """ë³€í™˜ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print(f"\nğŸ“Š ë³€í™˜ ê²°ê³¼ ìš”ì•½ (ê¹Šì´: {self.research_depth}):")
        print(f"ğŸ‘¤ ì´ë¦„: {profile.get('personal_info', {}).get('name', 'ë¯¸í™•ì¸')}")
        print(f"ğŸ“ í•™ë ¥: {len(profile.get('education', []))}ê°œ")
        print(f"ğŸ’¼ ê²½ë ¥: {len(profile.get('work_experience', []))}ê°œ")
        print(f"ğŸš€ í”„ë¡œì íŠ¸: {len(profile.get('projects', []))}ê°œ")
        print(f"ğŸ† ìê²©ì¦: {len(profile.get('certifications', []))}ê°œ")
        print(f"ğŸ¥‡ ìˆ˜ìƒ: {len(profile.get('awards', []))}ê°œ")
        
        # ê¸°ìˆ  ìŠ¤íƒ ìš”ì•½
        skills = profile.get('skills', {})
        total_skills = sum(len(v) for v in skills.values() if isinstance(v, list))
        print(f"ğŸ’» ê¸°ìˆ  ìŠ¤íƒ: {total_skills}ê°œ")
        
        # ë³€í™˜ í’ˆì§ˆ ì •ë³´
        conversion_method = profile.get('conversion_method', 'unknown')
        print(f"ğŸ”§ ë³€í™˜ ë°©ì‹: {conversion_method}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¤– ResumeAgents AI ì´ë ¥ì„œ ë³€í™˜ê¸°")
    print("="*50)
    print("ğŸ“‹ DEVELOPMENT_STRATEGY.md ê¸°ë°˜ í†µí•© ë³€í™˜ ë„êµ¬")
    print()
    
    # ì—°êµ¬ ê¹Šì´ ì„ íƒ
    print("ğŸ¯ ì—°êµ¬ ê¹Šì´ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. LOW    - ë¹ ë¥¸ ë³€í™˜ (gpt-4o-mini)")
    print("2. MEDIUM - ê· í˜•ì¡íŒ ë³€í™˜ (ê¸°ë³¸ê°’)")
    print("3. HIGH   - ì •ë°€ ë³€í™˜ (ê³ ê¸‰ ëª¨ë¸)")
    
    depth_choice = input("\nì„ íƒ (1-3) [ê¸°ë³¸ê°’: 2]: ").strip() or "2"
    depth_map = {"1": "LOW", "2": "MEDIUM", "3": "HIGH"}
    research_depth = depth_map.get(depth_choice, "MEDIUM")
    
    # ë³€í™˜ê¸° ì´ˆê¸°í™”
    try:
        converter = AIResumeConverter(research_depth=research_depth)
    except SystemExit:
        return
    
    # ì´ë ¥ì„œ íŒŒì¼ ì…ë ¥
    while True:
        file_path = input("\nğŸ“„ ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not file_path:
            print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        try:
            # íŒŒì¼ ì½ê¸°
            print(f"ğŸ“– íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤: {file_path}")
            resume_text = converter.read_resume_file(file_path)
            
            if not resume_text.strip():
                print("âŒ íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            print(f"âœ… íŒŒì¼ ì½ê¸° ì™„ë£Œ ({len(resume_text)} ë¬¸ì)")
            print(f"ğŸ“ ë¯¸ë¦¬ë³´ê¸°: {resume_text[:200]}...")
            
            break
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            continue
    
    # AI ë³€í™˜ ì‹¤í–‰
    try:
        profile = await converter.convert_resume_to_profile(resume_text)
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        converter.print_conversion_summary(profile)
        
        # íŒŒì¼ëª… ì…ë ¥
        default_name = profile.get('personal_info', {}).get('name', 'converted_profile')
        default_name = default_name.replace(' ', '_').replace('/', '_') if default_name else 'converted_profile'
        
        filename = input(f"\nğŸ’¾ ì €ì¥í•  íŒŒì¼ëª… (ê¸°ë³¸ê°’: {default_name}): ").strip() or default_name
        
        # íŒŒì¼ ì €ì¥
        filepath = converter.save_profile(profile, filename)
        
        print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {filepath}")
        print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {os.path.getsize(filepath)} bytes")
        
        print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"1. ì €ì¥ëœ JSON íŒŒì¼ì„ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •")
        print(f"2. ResumeAgents ì‹¤í–‰: python main.py")
        print(f"3. ì˜µì…˜ 2 ì„ íƒ: ê¸°ì¡´ í”„ë¡œí•„ ì‚¬ìš©")
        print(f"4. í”„ë¡œí•„ ì„ íƒ: {filename}")
        print(f"5. ì—°êµ¬ ê¹Šì´: {research_depth} ì‚¬ìš© ê¶Œì¥")
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ìˆ˜ë™ ë³€í™˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”:")
        print("   python -m resumeagents.utils.convert_resume")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main()) 